{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achal\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\achal\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "    \n",
    "print(\"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Boston housing dataset:\n",
      "\n",
      "Minimum price: $105,000.00\n",
      "Maximum price: $1,024,800.00\n",
      "Mean price: $454,342.94\n",
      "Median price $438,900.00\n",
      "Standard deviation of prices: $165,171.13\n"
     ]
    }
   ],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.min(prices)\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.max(prices)\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(prices)\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "# Show the calculated statistics\n",
    "print( \"Statistics for Boston housing dataset:\\n\")\n",
    "print (\"Minimum price: ${:,.2f}\".format(minimum_price))\n",
    "print( \"Maximum price: ${:,.2f}\".format(maximum_price))\n",
    "print (\"Mean price: ${:,.2f}\".format(mean_price))\n",
    "print (\"Median price ${:,.2f}\".format(median_price))\n",
    "print (\"Standard deviation of prices: ${:,.2f}\".format(std_price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'r2_score'\n",
    "from sklearn.metrics import r2_score\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true , y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a coefficient of determination, R^2, of 0.923.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the performance of this model\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs.ModelComplexity(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying when a model is suffering from high bias or high variance.\n",
    "\n",
    "It is easy to identify whether the model is suffering from a high bias or a high variance.\n",
    "High variance models have a gap between the training and validation scores.\n",
    "This is because it is able to fit the model well but unable to generalize well resulting in a high training score but low validation score.\n",
    "High bias models have have a small or no gap between the training and validations scores.\n",
    "This is because it is unable to fit the model well and unable to generalize well resulting in both scores converging to a similar low score.\n",
    "\n",
    "Maximum depth of 1: High Bias\n",
    "\n",
    "Both training and testing scores are low.\n",
    "There is barely a gap between the training and testing scores.\n",
    "This indicates the model is not fitting the dataset well and not generalizing well hence the model is suffering from high bias.\n",
    "\n",
    "Maximum depth of 10: High Variance\n",
    "\n",
    "Training score is high. Testing score is low\n",
    "There is a substantial gap between the training and testing scores.\n",
    "This indicates the model is fitting the dataset well but not generalizing well hence the model is suffering from high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# Import 'train_test_split'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test =train_test_split(features,prices, test_size = 0.20, random_state=10)\n",
    "# Success\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achal\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "\n",
    "    # Cross-validation sets from the training data\n",
    "    # X.shape[0] is the total number of elements\n",
    "    # n_iter is the number of re-shuffling & splitting iterations.\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Decision tree regressor object\n",
    "    # Instantiate\n",
    "    regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "    # Dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = dict(max_depth=[1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    # We initially created performance_metric using R2_score\n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # grid search object\n",
    "    grid = GridSearchCV(regressor, params, cv=cv_sets, scoring=scoring_fnc) \n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 4 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(X_train, y_train)\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $304,500.00\n",
      "Predicted selling price for Client 2's home: $406,933.33\n",
      "Predicted selling price for Client 3's home: $938,053.85\n"
     ]
    }
   ],
   "source": [
    "# Produce a matrix for client data\n",
    "client_data = [[5, 17, 6], # Client 1\n",
    "               [4, 32, 18], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(reg.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
